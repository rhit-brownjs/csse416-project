{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5214c11-6de7-4b30-a5f1-0a25b7e4fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: 391043.97\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "# Load the pre-trained XGBoost model\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model(\"xgb_model.json\")\n",
    "\n",
    "# Load the pretrained VGG16 model. Setting `pretrained=True` loads weights trained on ImageNet.\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "# We only need the features, so we remove the classifier part by taking only `model.features`.\n",
    "model = model.features\n",
    "# Set the model to evaluation mode to prevent training-related behavior, such as dropout.\n",
    "model.eval()\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VGG16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # VGG16 normalization\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to extract features from the image\n",
    "def extract_features(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return np.zeros(4096)  # Return a zero vector if image is not found or corrupted\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# Prepare the text features\n",
    "def preprocess_text_features(features):\n",
    "    return np.array(features).reshape(1, -1)  # Ensure it is a 2D array\n",
    "\n",
    "# Combine image and text features\n",
    "image_path = \"data/socal_pics/48.jpg\"\n",
    "image_features = extract_features(image_path)\n",
    "text_features = preprocess_text_features([6400, 14, 5, 4])\n",
    "\n",
    "# Concatenate all features\n",
    "all_features = np.concatenate([image_features, text_features.flatten()])\n",
    "\n",
    "# Predict with the XGBoost model\n",
    "dtest = xgb.DMatrix(all_features.reshape(1, -1))\n",
    "predicted_price = xgb_model.predict(dtest)\n",
    "\n",
    "print(\"Predicted Price:\", predicted_price[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e281f-9bb0-4e3e-8b0a-781cda22c1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
