{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c3ee18-fce5-4fd4-959b-69630a5a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import lstsq, solve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4926d475-b42e-44ce-9f7e-27a3fcc00bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>street</th>\n",
       "      <th>citi</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1317 Van Buren Avenue</td>\n",
       "      <td>Salton City, CA</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1560</td>\n",
       "      <td>201900</td>\n",
       "      <td>data/socal_pics\\0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124 C Street W</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713</td>\n",
       "      <td>228500</td>\n",
       "      <td>data/socal_pics\\1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2304 Clark Road</td>\n",
       "      <td>Imperial, CA</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>273950</td>\n",
       "      <td>data/socal_pics\\2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>755 Brawley Avenue</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>350000</td>\n",
       "      <td>data/socal_pics\\3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2207 R Carrillo Court</td>\n",
       "      <td>Calexico, CA</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2547</td>\n",
       "      <td>385100</td>\n",
       "      <td>data/socal_pics\\4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                 street             citi  n_citi  bed  bath  sqft  \\\n",
       "0         0  1317 Van Buren Avenue  Salton City, CA     317    3   2.0  1560   \n",
       "1         1         124 C Street W      Brawley, CA      48    3   2.0   713   \n",
       "2         2        2304 Clark Road     Imperial, CA     152    3   1.0   800   \n",
       "3         3     755 Brawley Avenue      Brawley, CA      48    3   1.0  1082   \n",
       "4         4  2207 R Carrillo Court     Calexico, CA      55    4   3.0  2547   \n",
       "\n",
       "    price             image_path  \n",
       "0  201900  data/socal_pics\\0.jpg  \n",
       "1  228500  data/socal_pics\\1.jpg  \n",
       "2  273950  data/socal_pics\\2.jpg  \n",
       "3  350000  data/socal_pics\\3.jpg  \n",
       "4  385100  data/socal_pics\\4.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/socal.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Folder where the images are stored\n",
    "image_folder = 'data/socal_pics'\n",
    "\n",
    "# Create a new column 'image_path' by constructing the path based on 'image_id'\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f334d9-1196-4184-8ac7-0c2dd3ad7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealEstateDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.data.iloc[idx]['image_id']\n",
    "        image_path = f\"{self.image_folder}/{image_id}.jpg\"\n",
    "\n",
    "        # Check if the image file exists\n",
    "        if os.path.exists(image_path):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        else:\n",
    "            print(f\"Warning: Image {image_path} not found. Using a blank image.\")\n",
    "            image = Image.new('RGB', (64, 64), color=(255, 255, 255))  # Create a blank image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sqft = torch.tensor(self.data.iloc[idx]['sqft'], dtype=torch.float32)\n",
    "        price = torch.tensor(self.data.iloc[idx]['price'], dtype=torch.float32)\n",
    "\n",
    "        return image, sqft, price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aec050-d20d-48d0-9e56-5b0f4c904050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PricePredictor, self).__init__()\n",
    "\n",
    "        # CNN for image processing, designed for 256x256 input images\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # Output: 128x128\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # Output: 64x64\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # Output: 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # Output: 16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # Output: 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # Output: 4x4\n",
    "\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Calculate the output size of the CNN by running a test tensor\n",
    "        test_tensor = torch.randn(1, 3, 256, 256)  # Simulate a 256x256 input image\n",
    "        cnn_output = self.cnn(test_tensor)\n",
    "        self.cnn_output_size = cnn_output.shape[1]  # Dynamically get the flattened size\n",
    "\n",
    "        # Fully connected layer for `sqft`\n",
    "        self.fc_sqft = nn.Linear(1, 64)\n",
    "\n",
    "        # Final layers for combined data\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(self.cnn_output_size + 64, 128),  # Combine CNN and sqft features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Output layer for price\n",
    "        )\n",
    "\n",
    "    def forward(self, image, sqft):\n",
    "        # CNN part for image\n",
    "        img_features = self.cnn(image)\n",
    "\n",
    "        # Fully connected layer for sqft\n",
    "        sqft_features = self.fc_sqft(sqft.view(-1, 1))\n",
    "\n",
    "        # Concatenate both features\n",
    "        combined_features = torch.cat((img_features, sqft_features), dim=1)\n",
    "\n",
    "        # Pass through final layers\n",
    "        price = self.fc_combined(combined_features)\n",
    "\n",
    "        return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f4ad55-bd82-402f-b5d6-fa337e4d502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 78756610048.0000\n",
      "Epoch [2/10], Loss: 45900976128.0000\n",
      "Epoch [3/10], Loss: 136016019456.0000\n",
      "Epoch [4/10], Loss: 71221051392.0000\n",
      "Epoch [5/10], Loss: 60624424960.0000\n",
      "Epoch [6/10], Loss: 71590608896.0000\n",
      "Epoch [7/10], Loss: 72826494976.0000\n",
      "Epoch [8/10], Loss: 67494244352.0000\n",
      "Epoch [9/10], Loss: 171699077120.0000\n",
      "Epoch [10/10], Loss: 91075543040.0000\n"
     ]
    }
   ],
   "source": [
    "# Define transform for 256x256 input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "csv_file = 'data/socal.csv'\n",
    "image_folder = 'data/socal_pics'\n",
    "dataset = RealEstateDataset(csv_file, image_folder, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = PricePredictor()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, sqft, prices in dataloader:\n",
    "        # Forward pass\n",
    "        predictions = model(images, sqft)\n",
    "        loss = criterion(predictions.view(-1), prices)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7a47e-fc7b-42b1-b079-3eca8ede3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "\n",
    "# Load the data\n",
    "file_path = 'data/socal.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Folder where the images are stored\n",
    "image_folder = 'data/socal_pics'\n",
    "\n",
    "# Create a new column 'image_path' by constructing the path based on 'image_id'\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VGG16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # VGG16 normalization\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load pre-trained VGG16 model and modify it to output features\n",
    "vgg16 = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "vgg16.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-1])\n",
    "vgg16.eval()\n",
    "\n",
    "def extract_features(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return np.zeros(4096)  # Return a zero vector if image is not found or corrupted\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = vgg16(image)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# Extract image features\n",
    "image_features_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    features = extract_features(image_path)\n",
    "    image_features_list.append(features)\n",
    "\n",
    "# Convert list to numpy array\n",
    "image_features = np.array(image_features_list)\n",
    "\n",
    "# Prepare numerical features\n",
    "numerical_features = df[['bed', 'bath', 'sqft']].values\n",
    "\n",
    "# Concatenate image features and numerical features\n",
    "X = np.concatenate((image_features, numerical_features), axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = df['price'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d60745-9571-4aeb-b124-e44ba46f710c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
