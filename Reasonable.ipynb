{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c3ee18-fce5-4fd4-959b-69630a5a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4926d475-b42e-44ce-9f7e-27a3fcc00bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = 'data/socal.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Folder where the images are stored\n",
    "image_folder = 'data/socal_pics'\n",
    "\n",
    "# Create a new column 'image_path' by constructing the path based on 'image_id'\n",
    "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f334d9-1196-4184-8ac7-0c2dd3ad7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VGG16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # VGG16 normalization\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9759a0cb-afa4-44d9-9e1d-bfa8259ea86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained VGG16 model. Setting `pretrained=True` loads weights trained on ImageNet.\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "# We only need the features, so we remove the classifier part by taking only `model.features`.\n",
    "model = model.features\n",
    "# Set the model to evaluation mode to prevent training-related behavior, such as dropout.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f4ad55-bd82-402f-b5d6-fa337e4d502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return np.zeros(4096)  # Return a zero vector if image is not found or corrupted\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb7a47e-fc7b-42b1-b079-3eca8ede3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image features\n",
    "image_features_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    features = extract_features(image_path)\n",
    "    image_features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d60745-9571-4aeb-b124-e44ba46f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to numpy array\n",
    "image_features = np.array(image_features_list)\n",
    "\n",
    "# Save the image features to a numpy .npz file using np.savez\n",
    "np.savez('image_features.npz', image_features=image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48eacd45-510f-4cd8-87d7-50c467992897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 8.67146494922878e+26\n",
      "Root Mean Squared Error (RMSE): 29447351237808.777\n"
     ]
    }
   ],
   "source": [
    "# Train linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ccceae-7ea3-4da9-903e-110f87151de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch dataset\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self,features,targets):\n",
    "        self.features = torch.tensor(features,dtype=torch.float32)\n",
    "        self.targets  = torch.tensor(targets,dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "    \n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetRegressor(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=64, output_size=2):\n",
    "        super(NeuralNetRegressor, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input layer -> Hidden layer\n",
    "        self.relu = nn.ReLU()                          # Activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Hidden layer -> Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)    # Input to hidden\n",
    "        x = self.relu(x)   # ReLU activation\n",
    "        x = self.fc2(x)    # Hidden to output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411598dc-ce1f-4990-9a2e-68170d392116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, yhat):\n",
    "    return np.mean((y - yhat) ** 2)\n",
    "\n",
    "def RMSE(y,yhat):\n",
    "    return np.sqrt(MSE(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9809aba-c9cb-46be-8921-c49de8c14f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract numerical features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_citi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbath\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Shape: (n_samples, 4)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Combine numerical features with image features\u001b[39;00m\n\u001b[0;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((numerical_features, image_features))  \u001b[38;5;66;03m# Shape: (n_samples, total_feature_dim)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract numerical features\n",
    "numerical_features = df[['sqft', 'n_citi', 'bed', 'bath']].values  # Shape: (n_samples, 4)\n",
    "\n",
    "# Combine numerical features with image features\n",
    "features = np.hstack((numerical_features, image_features))  # Shape: (n_samples, total_feature_dim)\n",
    "\n",
    "# Extract targets\n",
    "targets = df.price\n",
    "\n",
    "# Create PyTorch dataset\n",
    "X = features\n",
    "Y = targets.to_numpy()\n",
    "dataset = CreateDataset(X,Y)\n",
    "data_loader = DataLoader(dataset,batch_size=200,shuffle=True)\n",
    "\n",
    "# Determine the input size based on the combined features\n",
    "input_size = features.shape[1]\n",
    "\n",
    "# Create the model instance\n",
    "model = NeuralNetRegressor(input_size=input_size,hidden_size=32,output_size=1)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "cost_function = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 2400\n",
    "# Example of how to train the model (assuming you have your data loaders)\n",
    "for epoch in range(num_epochs):\n",
    "    for X,Y in data_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        Yh = model(X)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = cost_function(Yh,torch.unsqueeze(Y,1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 480 == 0:\n",
    "        print('epoch',epoch,'loss',loss.detach().numpy())\n",
    "        \n",
    "# neural network RMSE\n",
    "X = torch.tensor(features,dtype=torch.float32)\n",
    "Yh = model(X)\n",
    "Yh = Yh.detach().numpy().flatten() #GPT4 suggested change to add flatten to match shapes\n",
    "Y = targets.to_numpy()\n",
    "RMSE(Y,Yh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084dcf66-0303-4940-a9a9-e76a3feb629f",
   "metadata": {},
   "source": [
    "###### epoch 0 loss 530075580000.0\n",
    "#epoch 480 loss 71383040000.0\n",
    "#epoch 960 loss 79980945000.0\n",
    "#epoch 1440 loss 81245790000.0\n",
    "#epoch 1920 loss 69038590000.0\n",
    "#278979.65244980756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b6c934-4f85-43f5-a56e-15d10861b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 2060929.6903489055\n",
      "Training RMSE: 1435.593845887097\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(\"image_features.npz\")\n",
    "\n",
    "# Assuming the file contains an array under the key 'image_features'\n",
    "image_features = data['image_features']\n",
    "\n",
    "# Extract numerical features\n",
    "numerical_features = df[['sqft', 'n_citi', 'bed', 'bath']].values  # Shape: (n_samples, 4)\n",
    "\n",
    "# Combine numerical features with image features\n",
    "features = np.hstack((numerical_features, image_features))  # Shape: (n_samples, total_feature_dim)\n",
    "\n",
    "# Extract targets\n",
    "targets = df.price\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=3000,       # Number of boosting rounds\n",
    "    learning_rate=0.1,      # Step size shrinkage used to prevent overfitting\n",
    "    max_depth=5,            # Maximum depth of a tree\n",
    "    random_state=42,        # Seed for reproducibility\n",
    "    objective='reg:squarederror'  # Objective function for regression\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = xgb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b91e2f9-781f-4622-9196-d1af7e3d82c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 2060929.6903489055\n",
      "Training RMSE: 1435.593845887097\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for the training set\n",
    "train_mse = MSE(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)  # Root Mean Squared Error\n",
    "\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training RMSE:\", train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410b5d68-4c64-484a-a1df-a7adb2f3e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 59710451393.06767\n",
      "Validation RMSE: 244357.22087359658\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Calculate Mean Squared Error (or any other evaluation metric)\n",
    "mse = MSE(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)   # Root Mean Squared Error\n",
    "print(\"Validation MSE:\", mse)\n",
    "print(\"Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac3a6cb-6da7-408c-a47f-08e89919d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in XGBoost's native format\n",
    "xgb_model.save_model(\"xgb_model.json\")  # You can also use \"xgb_model.bin\" for binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bef38a-b758-40a4-bac6-ae93635fa0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
